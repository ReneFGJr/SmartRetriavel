# ===============================================================
# M√≥dulo: mod_thesa.py
# Fun√ß√£o: Verificar se palavra existe ou sugerir similar no vocabul√°rio
# Autor: Ren√© Faustino Gabriel Junior (adaptado por GPT-5)
# ===============================================================

import json
import sys
import unicodedata
import os
import re
import requests
from difflib import SequenceMatcher
from itertools import permutations


# === Normaliza√ß√£o ===
def normalizar(texto):
    """Remove acentos, coloca em min√∫sculas e limpa espa√ßos extras."""
    if not texto:
        return ""
    texto = unicodedata.normalize("NFD", texto)
    texto = "".join(c for c in texto if unicodedata.category(c) != "Mn")
    texto = texto.lower().strip()
    texto = re.sub(r"[^a-z0-9√°√©√≠√≥√∫√£√µ√ß\s-]", "", texto)
    return texto


# === Gera vocabul√°rio .vc ===
def processar_json(json_text, id="local"):
    """L√™ JSON do Thesa e gera vocabul√°rio controlado (.vc)."""
    data = json.loads(json_text)
    termos_data = data.get("terms", [])
    termos = set()

    for item in termos_data:
        termo = item.get("Term")
        if termo:
            termos.add(normalizar(termo))

    os.makedirs("data", exist_ok=True)
    output_file = f"data/vc_{id}.vc"

    termos_ordenados = sorted(termos)
    with open(output_file, "w", encoding="utf-8") as f:
        for termo in termos_ordenados:
            f.write(termo + "\n")

    print(
        f"üíæ Arquivo '{output_file}' criado com {len(termos_ordenados)} termos."
    )
    return output_file


# === Extrai palavras √∫nicas ===
def extrair_sintagmas(input_file, id="local"):
    """Gera lista de palavras √∫nicas a partir de um vocabul√°rio."""
    palavras = set()
    with open(input_file, "r", encoding="utf-8") as f:
        for linha in f:
            linha = linha.strip()
            if not linha:
                continue
            tokens = re.split(r"[\s\-]+", linha)
            for token in tokens:
                token = normalizar(token)
                if len(token) > 2:
                    palavras.add(token)

    output_file = f"data/vc_words_{id}.vc"
    with open(output_file, "w", encoding="utf-8") as f:
        for p in sorted(palavras):
            f.write(p + "\n")

    print(
        f"üíæ Arquivo '{output_file}' criado com {len(palavras)} palavras √∫nicas."
    )
    return output_file


def distancia_levenshtein(a, b):
    """Calcula a dist√¢ncia de Levenshtein entre duas palavras."""
    m, n = len(a), len(b)
    dp = [[0] * (n + 1) for _ in range(m + 1)]

    for i in range(m + 1):
        dp[i][0] = i
    for j in range(n + 1):
        dp[0][j] = j

    for i in range(1, m + 1):
        for j in range(1, n + 1):
            custo = 0 if a[i - 1] == b[j - 1] else 1
            dp[i][j] = min(
                dp[i - 1][j] + 1,  # remo√ß√£o
                dp[i][j - 1] + 1,  # inser√ß√£o
                dp[i - 1][j - 1] + custo  # substitui√ß√£o
            )

    return dp[m][n]

def verificar_palavra(palavras):
    print("üî§ Palavra:", palavras)
    wordsX = gerar_permutacoes(palavras)
    print(wordsX)
    sys.exit()

def verificar_palavra_busca(palavra, voc_file="data/vc_words_6.vc", max_distancia=5):
    """
    Verifica se a palavra existe no vocabul√°rio.
    Se n√£o existir, procura similar com dist√¢ncia de Levenshtein <= max_distancia.
    """
    palavra = normalizar(palavra)

    if not os.path.exists(voc_file):
        raise FileNotFoundError(
            f"Arquivo de vocabul√°rio n√£o encontrado: {voc_file}")

    with open(voc_file, "r", encoding="utf-8") as f:
        vocabulario = [linha.strip() for linha in f if linha.strip()]

    # 1Ô∏è‚É£ Verifica exist√™ncia exata
    if palavra in vocabulario:
        print(f"‚úÖ '{palavra}' encontrado no vocabul√°rio.")
        return palavra

    # 2Ô∏è‚É£ Busca palavra mais pr√≥xima
    melhor_match = None
    menor_dist = 9999

    for termo in vocabulario:
        dist = distancia_levenshtein(palavra, termo)
        if dist < menor_dist:
            menor_dist = dist
            melhor_match = termo

    if menor_dist <= max_distancia:
        print(
            f"‚ùì '{palavra}' n√£o encontrado. Palavra mais pr√≥xima: '{melhor_match}' (dist√¢ncia {menor_dist})"
        )
        return melhor_match
    else:
        print(f"‚ùå '{palavra}' n√£o encontrado e sem similaridade pr√≥xima.")
        return None


def soundex_portugues(palavra):
    """Gera c√≥digo Soundex simplificado adaptado ao portugu√™s."""
    palavra = normalizar(palavra)
    if not palavra:
        return ""

    # Mapeamento fon√©tico b√°sico
    mapa = {
        "b": "1",
        "f": "1",
        "p": "1",
        "v": "1",
        "c": "2",
        "g": "2",
        "j": "2",
        "k": "2",
        "q": "2",
        "s": "2",
        "x": "2",
        "z": "2",
        "d": "3",
        "t": "3",
        "l": "4",
        "m": "5",
        "n": "5",
        "r": "6"
    }

    primeira = palavra[0].upper()
    codigos = [mapa.get(letra, "") for letra in palavra[1:]]
    codigo = [primeira]
    for c in codigos:
        if not codigo or c != codigo[-1]:
            codigo.append(c)
    codigo = "".join(codigo)
    codigo = (codigo + "0000")[:4]
    return codigo


def verificar_palavra_inteligente(palavra,
                                  voc_file="data/vc_words_6.vc",
                                  max_distancia=2,
                                  max_diff_len=3):
    """
    Verifica se a palavra existe no vocabul√°rio.
    Regras:
    1Ô∏è‚É£ Verifica se o n√∫mero de caracteres √© pr√≥ximo.
    2Ô∏è‚É£ Se sim, usa dist√¢ncia de Levenshtein (erros de digita√ß√£o).
    3Ô∏è‚É£ Se n√£o encontrar, tenta Soundex (similaridade fon√©tica).
    """
    palavra = normalizar(palavra)

    if not os.path.exists(voc_file):
        raise FileNotFoundError(
            f"Arquivo de vocabul√°rio n√£o encontrado: {voc_file}")

    with open(voc_file, "r", encoding="utf-8") as f:
        vocabulario = [linha.strip() for linha in f if linha.strip()]

    # === 1Ô∏è‚É£ Verifica exist√™ncia exata ===
    if palavra in vocabulario:
        print(f"‚úÖ '{palavra}' encontrado no vocabul√°rio.")
        return palavra

    # === 2Ô∏è‚É£ Fun√ß√£o auxiliar: dist√¢ncia de Levenshtein ===
    def distancia_levenshtein(a, b):
        m, n = len(a), len(b)
        dp = [[0] * (n + 1) for _ in range(m + 1)]
        for i in range(m + 1):
            dp[i][0] = i
        for j in range(n + 1):
            dp[0][j] = j
        for i in range(1, m + 1):
            for j in range(1, n + 1):
                custo = 0 if a[i - 1] == b[j - 1] else 1
                dp[i][j] = min(dp[i - 1][j] + 1, dp[i][j - 1] + 1,
                               dp[i - 1][j - 1] + custo)
        return dp[m][n]

    # === 3Ô∏è‚É£ Fun√ß√£o auxiliar: Soundex simplificado ===
    def soundex_portugues(palavra):
        palavra = normalizar(palavra)
        if not palavra:
            return ""
        mapa = {
            "b": "1",
            "f": "1",
            "p": "1",
            "v": "1",
            "c": "2",
            "g": "2",
            "j": "2",
            "k": "2",
            "q": "2",
            "s": "2",
            "x": "2",
            "z": "2",
            "d": "3",
            "t": "3",
            "l": "4",
            "m": "5",
            "n": "5",
            "r": "6"
        }
        primeira = palavra[0].upper()
        codigos = [mapa.get(letra, "") for letra in palavra[1:]]
        codigo = [primeira]
        for c in codigos:
            if not codigo or c != codigo[-1]:
                codigo.append(c)
        codigo = "".join(codigo)
        codigo = (codigo + "0000")[:4]
        return codigo

    palavra_soundex = soundex_portugues(palavra)

    melhor_match = None
    menor_dist = 999
    melhor_fonetico = None

    for termo in vocabulario:
        # === Regra 1: diferen√ßa de tamanho ===
        if abs(len(palavra) - len(termo)) > max_diff_len:
            continue

        # === Regra 2: dist√¢ncia de Levenshtein ===
        dist = distancia_levenshtein(palavra, termo)
        if dist < menor_dist:
            menor_dist = dist
            melhor_match = termo

        # === Regra 3: fon√©tica ===
        if soundex_portugues(termo) == palavra_soundex:
            melhor_fonetico = termo

    # === Resultado ===
    if menor_dist <= max_distancia:
        print(
            f"‚ùì '{palavra}' n√£o encontrado. Palavra mais pr√≥xima: '{melhor_match}' (dist√¢ncia {menor_dist})"
        )
        return melhor_match
    elif melhor_fonetico:
        print(
            f"üîä '{palavra}' n√£o encontrado. Palavra mais pr√≥xima (fon√©tica): '{melhor_fonetico}'"
        )
        return melhor_fonetico
    else:
        print(f"‚ùå '{palavra}' n√£o encontrado e sem similaridade pr√≥xima.")
        return None


# === Execu√ß√£o direta ===
if __name__ == "__main__":
    print("üìÅ Diret√≥rio atual:", os.getcwd())

    url = "https://www.ufrgs.br/thesa/api/terms/6"
    print(f"üîó Acessando: {url}")
    response = requests.get(url)

    if response.status_code == 200:
        text = response.text
        vc_file = processar_json(text, id="6")
        extrair_sintagmas(vc_file, id="6")

        # üîé Testes de verifica√ß√£o
        verificar_palavra("inteligencia")  # existe
        verificar_palavra("intelgencia")  # erro de digita√ß√£o
        verificar_palavra("inteligencio")  # pequeno erro
        verificar_palavra("ChatGTP")  # similar
        verificar_palavra("chatFTP")  # pode ou n√£o existir
        verificar_palavra("bais")  # pode ou n√£o existir
        verificar_palavra_inteligente("bais")  # pode ou n√£o existir

    else:
        print(f"‚ùå Erro ao acessar a URL: {response.status_code}")

    # === Exemplo de uso ===
    palavra = "bias"
    resultado = gerar_permutacoes(palavra)

    print(f"üî§ Palavra: {palavra}")
    print(f"üß© Total de combina√ß√µes: {len(resultado)}")
    print("üìú Algumas combina√ß√µes:")
    print(resultado[:10])  # Mostra apenas as 10 primeiras
